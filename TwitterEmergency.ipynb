{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref - https://www.kaggle.com/marcovasquez/basic-nlp-with-tensorflow-and-wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rajku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Natural Language Tool Kit \n",
    "import nltk  \n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "submission = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "def remove_html(text):\n",
    "    no_html= pattern.sub('',text)\n",
    "    return no_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all text that start with html\n",
    "train['text']=train['text'].apply(lambda x : remove_html(x))\n",
    "test['text']=test['text'].apply(lambda x : remove_html(x))\n",
    "train.loc[train['text'].str.contains('http')].target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(dataset):\n",
    "    corpus = []  \n",
    "    for i in range(0, len(dataset)):  \n",
    "        text = re.sub('[^a-zA-Z]', ' ', dataset['text'][i])  \n",
    "        text = text.lower()  \n",
    "        # split to array(default delimiter is \" \") \n",
    "        text = text.split()\n",
    "        cleantext = []\n",
    "        for t in text:\n",
    "            if (len(text)) <= 2:\n",
    "                continue\n",
    "            cleantext.append(t)\n",
    "        text = ' '.join(cleantext)    \n",
    "        corpus.append(text)  \n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = clean_text(train)\n",
    "test['text'] = clean_text(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5390825a4cd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: True"
     ]
    }
   ],
   "source": [
    "train = train[len(train['text']) > 0]\n",
    "test = test[len(test['text']) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-83e17d800f0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: True"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(train.text.values)\n",
    "idf = vectorizer.idf_\n",
    "idf_vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['our deeds are the reason of this earthquake may allah forgive us all',\n",
       "       'forest fire near la ronge sask canada',\n",
       "       'all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected',\n",
       "       ..., 'm utc km s of volcano hawaii',\n",
       "       'police investigating after an e bike collided with a car in little portugal e bike rider suffered serious non life threatening injuries',\n",
       "       'the latest more homes razed by northern california wildfire abc news'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec([x.split() for x in train.text.values], min_count=1, size=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.3970828 ,  0.38387552,  0.5734416 ,  0.17056273,  0.6775423 ,\n",
       "       -0.6026293 ,  0.33637473,  1.4864889 , -2.1781757 ,  0.95379776,\n",
       "       -0.78529286, -0.86143005, -3.1887312 , -0.47411925, -0.10404182,\n",
       "       -1.3211287 , -1.9210428 ,  0.319292  ,  0.26214236,  3.220421  ,\n",
       "       -1.9736892 , -0.61150783,  0.5784559 ,  0.26379704, -0.60832703],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['fire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.21071720e+00,  2.60898083e-01,  3.72877866e-01, ...,\n",
       "         3.41873437e-01,  1.82068110e-01, -4.26021188e-01],\n",
       "       [-3.90440114e-02,  8.47781356e-03,  3.31667485e-03, ...,\n",
       "        -4.62460332e-04,  5.49084926e-03,  1.09213050e-02],\n",
       "       [-3.80412698e+00,  5.28449774e-01,  5.73879004e-01, ...,\n",
       "         4.61733639e-01,  3.36226344e-01, -6.95806146e-01],\n",
       "       ...,\n",
       "       [-2.32012607e-02, -4.11880529e-03,  2.03537159e-02, ...,\n",
       "        -1.56162055e-02,  4.64843307e-03, -3.99249082e-04],\n",
       "       [-2.39132028e-02,  1.21059758e-03, -7.33341929e-03, ...,\n",
       "         1.48042040e-02,  1.10401539e-02, -1.51642901e-03],\n",
       "       [-3.64758968e-02,  1.65267233e-02,  3.30372131e-03, ...,\n",
       "         1.01493904e-02, -3.83380614e-03,  1.35103799e-02]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[model.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "i = 1\n",
    "embedding = []\n",
    "embeddings_dict['unk'] = 0\n",
    "word_idx = {}\n",
    "word_idx[0] = 'unk'\n",
    "embedding.append(np.zeros(embedding_dim, dtype=int))\n",
    "for key, _ in model.wv.vocab.items():\n",
    "    embeddings_dict[key] = i\n",
    "    word_idx[i] = key\n",
    "    i += 1\n",
    "    embedding.append(model.wv[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in idf_vocab.items():\n",
    "    model.wv[key] = model.wv[key] * idf[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.802179045860704"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf[idf_vocab['this']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-15.24171   ,   1.7223363 ,   2.5728636 ,   0.7652647 ,\n",
       "         3.0399327 ,  -2.70382   ,   1.5092143 ,   6.669438  ,\n",
       "        -9.772833  ,   4.2794094 ,  -3.5233777 ,  -3.8649828 ,\n",
       "       -14.306897  ,  -2.1272333 ,  -0.46680498,  -5.927515  ,\n",
       "        -8.619153  ,   1.4325691 ,   1.1761556 ,  14.44908   ,\n",
       "        -8.855362  ,  -2.7436554 ,   2.5953612 ,   1.1835796 ,\n",
       "        -2.7293842 ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['fire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emergency', 0.9998307824134827),\n",
       " ('new', 0.9998186826705933),\n",
       " ('on', 0.9997924566268921),\n",
       " ('people', 0.9997823238372803),\n",
       " ('destruction', 0.9997754096984863),\n",
       " ('the', 0.999773383140564),\n",
       " ('news', 0.9997650384902954),\n",
       " ('at', 0.999754786491394),\n",
       " ('from', 0.9997519254684448),\n",
       " ('crash', 0.99974524974823)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "        self.fc1 = nn.Linear(embed_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        self.output = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def __init__(self, num_embeddings, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(num_embeddings, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embed_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        self.output = nn.Sigmoid()\n",
    "        self.embedding.weight.data.uniform_(-0.5, 0.5)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        self.init_weights()\n",
    "                  \n",
    "        \n",
    "    def forward(self, input, offsets):\n",
    "        #print(input)\n",
    "        #print(self.embedding.weight[1:3])\n",
    "        embedded = self.embedding(input, offsets)\n",
    "        h1 = F.tanh(self.fc1(embedded))\n",
    "        h2 = self.fc2(h1)\n",
    "        return self.output(h2)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc2.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataSet(Dataset):    \n",
    "    def __init__(self, input, labels, vocab, isFixed, size):\n",
    "        self.vocab = vocab\n",
    "        self.data = []\n",
    "        for i in range(len(input)):\n",
    "            line = input[i]\n",
    "            tokens = [self.vocab[token] if token in self.vocab else self.vocab['unk'] for token in line]\n",
    "            self.data.append((labels[i], tokens))\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __getlabel__(self, index):\n",
    "        return this.labels[index]\n",
    "    \n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def getvocab(self):\n",
    "        return self.vocab\n",
    "    \n",
    "    def getTensor(self, sentence):\n",
    "        tokens = sentence.split()\n",
    "        tokens = torch.tensor([[self.vocab[token] if token in self.vocab else self.vocab['unk'] for token in tokens]])\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] * 1.0 for entry in batch])\n",
    "    text = [torch.tensor(entry[1]) for entry in batch]\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    print(text)\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_dateSet = TwitterDataSet(train.text.values, train.target.values, embeddings_dict, False, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffmodel = FeedForwardModel(embedding, embedding_dim)\n",
    "ffmodel = FeedForwardModel(len(twitter_dateSet.vocab), embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fuction = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(ffmodel.parameters(), lr=2.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_dateSet.vocab['fire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1566,  0.0740,  0.2386, -0.3681, -0.3893, -0.2133, -0.3776, -0.3680,\n",
       "         0.3299,  0.3512,  0.4521,  0.2492,  0.1608,  0.0850,  0.1175,  0.2592,\n",
       "        -0.2391,  0.4796, -0.4645,  0.2887,  0.1292,  0.1851,  0.1179,  0.4575,\n",
       "        -0.1870], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffmodel.embedding.weight[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffmodel.embedding.weight[11:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffmodel.embedding.weight[11:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffmodel.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After training\n",
    "#ffmodel.embedding.weight[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0.0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        output = ffmodel(text, offsets)\n",
    "        loss = loss_fuction(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        outputLabel = (output > 0.5).float()\n",
    "        outputLabel = outputLabel.view(-1)\n",
    "        train_acc += ((outputLabel == cls).float()).sum()\n",
    "        count = count + len(cls)\n",
    "        #print('outputLength : %d train_acc %f count %f acc %f' %(len(outputLabel), train_acc, count, train_acc/count))\n",
    "        #print('%f' %(train_acc/count))\n",
    "        #print(train_acc)\n",
    "        #print(train_acc)\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss/count, train_acc/count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_func(sub_valid_):\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    count = 0.0\n",
    "    data = DataLoader(sub_valid_, batch_size=BATCH_SIZE, shuffle=True,collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        output = ffmodel(text, offsets)\n",
    "        loss = loss_fuction(output, cls)\n",
    "        valid_loss += loss.item()\n",
    "        outputLabel = (output > 0.5).float()\n",
    "        outputLabel = outputLabel.view(-1)\n",
    "        valid_acc += ((outputLabel == cls).float()).sum()\n",
    "        count = count + len(cls)\n",
    "    return valid_loss/count, valid_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 152, 1087, 2715,    0,  887,   76,  295, 1534,    0,  152, 1087,   52,\n",
      "         152,    0,   76,    0,  413,   52,  469,  469,   52,    0,   86,   52,\n",
      "        2185, 2715,    0,   76,   86,    0, 1534,   76,  376, 2715,    0,   52,\n",
      "           0,  220,   52,  469,  887, 2715,  295,    0,  152,  789,    0,   77,\n",
      "        2728,    0, 1087, 2715,   52, 1534,  152, 1087,    0,  152,  295, 2728,\n",
      "           0, 1535, 2715,   76,  469,  887,    0,  413,   76,  152, 1087,    0,\n",
      "          86,  789,   77, 2715, 1535,  789,  220, 2728,    0,  152, 1087,   52,\n",
      "         152,    0,  413,   52,  469,  469,   52,    0, 1535, 2715,    0,   86,\n",
      "         789,   77, 2715, 1535,  789,  220, 2728,    0, 2715, 1534,   86, 2715]), tensor([ 152,  789,    0,  469,   52, 2185,   76,  887,   52,  152, 2715,    0,\n",
      "          76,  469, 2715, 2185,   76,  152,   52, 1535, 1534, 2715,    0,  764,\n",
      "         763, 1087, 2715,   52, 2185,   52, 1534,    0,   76,  469,  152, 2715,\n",
      "         295,  469,   52, 1534,    0,   52,  764,  220,   76,  152,    0,   77,\n",
      "         764,   86,  152,    0, 1534, 2715,   52,  220,    0,  152, 1087, 2715,\n",
      "           0,  413,   52, 2728]), tensor([2787,   86,   52,  295, 2715,   86,  764,    0,   52,   77, 2715,  295,\n",
      "          76, 2787,   52,  469,    0,  152,  295,   52,  887, 2715,  220, 2728]), tensor([ 220, 2715,   52,  220,    0,  220,  789, 2318, 2715,  469,   86,    0,\n",
      "          76,  469, 1017,  764,  295, 2715,  220,    0,   76,  469,    0,  887,\n",
      "          52, 2318,   52,    0, 1535, 1534,   52,   86,  152,    0,  469, 2715,\n",
      "          52,  295,    0, 1087,  789,  764,   86, 2715,    0, 1534, 2715, 2185,\n",
      "        2715, 1534, 2715,  220,    0,   76,  469,    0,   86,  764,   77,   77,\n",
      "        2715,  295,    0,  413,   52,  295,    0, 2185,   76,   52]), tensor([ 763,   52,  469,  220, 2715,   77,  789,  469,   76,  764,   77,    0,\n",
      "          76,  469,    0,   52, 1535,   52,    0,   52,   86,    0,  413,  789,\n",
      "          77,   52,  469,    0,  220, 2715, 1534,   76, 2185, 2715,  295,   86,\n",
      "           0, 1535,   52, 1535, 2728,    0,  413,   76,  152, 1087,  789,  764,\n",
      "         152,    0, 2520,   52, 2787, 2715,    0,  763, 1087,  789,  152,  789,\n",
      "          86]), tensor([2715,  469,  152,   76,  295, 2715,    0,  152,  789,  413,  469,    0,\n",
      "         789, 2520,    0,  295,  789,  789,   86, 2715, 2185, 2715, 1534,  152,\n",
      "           0,  413,   52,   86, 1087,    0, 2715, 2185,   52, 2787,  764,   52,\n",
      "         152, 2715,  220,    0, 1535, 2715, 2787,   52,  764,   86, 2715,    0,\n",
      "         789, 2520,    0,  413,   76, 1534,  220, 2520,   76,  295, 2715]), tensor([]), tensor([  86,   76,   86,   77,  789,    0,  220, 2715,  152, 2715, 2787,  152,\n",
      "          52,  220,  789,    0, 1017,   52,  763,    0,  469,    0,   86, 2715,\n",
      "          76,   86,   77,   76, 2787,    0,   76,  469,  152, 2715,  469,   86,\n",
      "          76,  152, 2728,    0,   76,  413,   52,  152, 2715,    0,   77,   76,\n",
      "        2728,   52,  887,   76,    0, 1017,   86,  152]), tensor([ 152, 1087, 2715,    0,  763,  789,  152,  764,   86,    0, 2715, 2787,\n",
      "         789,  469,  789,   77, 2728,    0, 2787,  789,  469,  152,   76,  469,\n",
      "         764, 2715,   86,    0,  152,  789,    0, 2787,  789, 1534, 1534,   52,\n",
      "         763,   86, 2715]), tensor([2520,   76,  295,   86,  152,    0,  469,   76,  887, 1087,  152,    0,\n",
      "         413,   76,  152, 1087,    0,  295, 2715,  152,   52,   76,  469, 2715,\n",
      "         295,   86,    0,   76,  469,    0,   76,  152,    0,   86,    0, 2274,\n",
      "         764,   76,  152, 2715,    0,  413, 2715,   76,  295,  220,    0, 1535,\n",
      "        2715,  152,  152, 2715,  295,    0,  887, 2715,  152,    0,  764,   86,\n",
      "        2715,  220,    0,  152,  789,    0,   76,  152,    0,   76,    0, 1087,\n",
      "          52, 2185, 2715,    0,  152,  789,    0,  413, 2715,   52,  295,    0,\n",
      "         152, 1087, 2715,   77,    0, 2715, 2185, 2715,  295, 2728,    0,   86,\n",
      "          76,  469,  887, 1534, 2715,    0,  469,   76,  887, 1087,  152,    0,\n",
      "        2520,  789,  295,    0,  152, 1087, 2715,    0,  469, 2715, 1409,  152,\n",
      "           0, 2728, 2715,   52,  295,    0,   52,  152,    0, 1534, 2715,   52,\n",
      "          86,  152]), tensor([ 220,   77,   52,   86,   86,   52,    0,  220, 2715, 2520,   76,  469,\n",
      "          76,  152, 2715,    0,  152,  295,   76,  763, 1534, 2715,    0, 2787,\n",
      "         295,  789,  413,  469,    0,  152, 1087,  295, 2715,   52,  152,    0,\n",
      "        1087,   76,   77,    0,   52,  469,  220,    0, 1087,   52,  295,  763,\n",
      "        2715,  295,    0, 1535,  789,  152, 1087]), tensor([  76,    0, 1017,  764,   86,  152,    0,  413,   52,  469,  469,   52,\n",
      "           0,   86,   77,  789,  376, 2715,    0,   86,  789,   77, 2715,    0,\n",
      "         413, 2715, 2715,  220,    0,   52,  469,  220,    0,  887, 2715,  152,\n",
      "           0,   86,  789,   77, 2715,    0, 2787,  789,   77,   77,   52,   86]), tensor([ 413,  789,  413,    0, 1087, 2715,    0, 2787,  295,  764,   86, 1087,\n",
      "        2715,  220,    0,  152, 1087,   52,  152,    0, 2715,  220,  413,   76,\n",
      "         469,  887,    0, 1535, 1534,  764, 2715, 1017,   52, 2728,   86]), tensor([  77, 2715,  469,    0, 2715,   86, 2787,   52,  763, 2715,    0, 2787,\n",
      "          52,  295,    0, 2715,  469,  887,  764, 1534, 2520, 2715,  220,    0,\n",
      "          76,  469,    0, 2520, 1534,   52,   77, 2715,   86,    0,   76,  469,\n",
      "           0,  763,   52,  295, 1534, 2715, 2728,    0,   86,    0, 2787,   52,\n",
      "         469, 2728,  789,  469,    0, 2787,  295, 2715,  413,   86,    0,   76,\n",
      "         469, 2185, 2715,   86,  152,   76,  887,   52,  152,   76,  469,  887,\n",
      "           0, 2787,   52,  764,   86, 2715]), tensor([  77, 1087,    0,   76,  469,  152,   52, 2787,  152,    0,  763,   52,\n",
      "         295,  152,    0, 1534,   76, 2520,  152,   86,    0,  789,  220,  220,\n",
      "          86,    0,  763, 1534,   52,  469, 2715,    0,  887, 1534,   76,  220,\n",
      "        2715,  220,    0,  469,  789,  152,    0, 2787,  295,   52,   86, 1087,\n",
      "        2715,  220,    0,   76,  469,  152,  789,    0,   86, 2715,   52]), tensor([  86, 1534,   86,   52,  469,  220,  763, 2715,  152,    0, 1087, 2715,\n",
      "        2728,    0,   86,   52, 1534, 1534, 2728,    0,   86,  789,  295,  295,\n",
      "        2728,    0, 1087,   52, 2185, 2715,    0, 2728,  789,  764,    0, 2715,\n",
      "          77,   52,   76, 1534, 2715,  220,    0,   77, 2715,    0, 1535, 2715,\n",
      "        2715,  469,    0,   52,  413,  789, 1534,    0, 1535, 1534,  789,  789,\n",
      "         220, 2728,    0,  413,  789,  295,  376,    0,   52,  295,  887, 1087,\n",
      "           0,  295, 2715,   86,   76,  887,  469,   76,  469,   86, 1087,   52,\n",
      "          77, 2715]), tensor([  86,  764,  763, 2715,  295,    0, 1534,  789,  764,  220,    0,  152,\n",
      "        1087,  764,  469,  220, 2715,  295,    0,  413,  789,  376, 2715,    0,\n",
      "          77, 2715,    0,  764,  763,    0, 2520,  295,  789,   77,    0,   77,\n",
      "        2728,    0, 2185, 2715,  295, 2728,    0,  469,   76, 2787, 2715,    0,\n",
      "         469,   52,  763]), tensor([  76,   77,   52,  887,   76,  469, 2715,    0,   52,  469,    0, 2715,\n",
      "         469,  152,   76,  295, 2715,    0,   52,   76,   86, 1534, 2715,    0,\n",
      "         220, 2715,  220,   76, 2787,   52,  152, 2715,  220,    0,  152,  789,\n",
      "           0,   77,   52,  376,   76,  469,  887,    0,  763, 2715,  789,  763,\n",
      "        1534, 2715,    0, 1534,  789,  789,  376,    0, 1534,   76,  376, 2715,\n",
      "           0,   86, 2715,  295, 1535,   76,   52,  469,    0,  295, 2715, 2520,\n",
      "         764,  887, 2715, 2715,   86,    0,  220,   76,  295, 2715, 2787,  152,\n",
      "         789,  295,    0,  789, 2520,    0,  413, 1087,  789, 1534, 2715,    0,\n",
      "        2520,  789,  789,  220,   86,    0, 2787, 1534,  789,  152, 1087,   76,\n",
      "         469,  887,    0,   86, 2715, 2787,  152,   76,  789,  469]), tensor([  86, 1534,  789,  763, 2715,  789, 2520, 1087,  789,  763, 2715,    0,\n",
      "          77,   52, 2728, 1535, 2715,    0,  152, 1087, 2715,    0,  763, 1534,\n",
      "          52,  469,    0,   76,   86,    0,  152,  789,    0,  220,   76, 1534,\n",
      "         764,  152, 2715,    0,  764,  469,  152,   76, 1534,    0,  152, 1087,\n",
      "        2715, 2728,    0, 2787,   52,  469,    0,   86,   52, 2520, 2715, 1534,\n",
      "        2728,    0,   86,   52, 2728,    0,  413, 2715,    0, 1087,   52, 2185,\n",
      "        2715,    0,  152,  789,    0,   86,  152,   52,  295,  152,    0, 2787,\n",
      "        1087,   52,  295,  887,   76,  469,  887,    0,  789,  295,    0,   76,\n",
      "         152,    0,   86,    0,  789, 2185, 2715,  295,    0, 1534,  789,  469,\n",
      "         887,   86,    0,  413,  789,  764, 1534,  220,    0, 2787,  789,   77,\n",
      "        2715,    0, 2520, 1534,  789,  789,  220,   76,  469,  887,    0,   76,\n",
      "         469]), tensor([ 152, 2715,  469,   86,   76,  789,  469,    0,   76,  469,    0, 1535,\n",
      "          52, 2728, 2715, 1534,   86,   52,    0,   52,   86,    0,  763,   52,\n",
      "         152,   76, 2715,  469, 2787, 2715,    0, 1017,  789,  469,   52,  152,\n",
      "        1087,   52,  469,    0,  763, 1534,   52,  469,   86,    0,  152,  789,\n",
      "           0, 1087,   76, 1017,   52, 2787,  376,    0,   52,  763, 2787,    0,\n",
      "         763,  220,  763]), tensor([ 469, 2715,  413,   86,    0,   86, 2787,   76, 2715,  469, 2787, 2715,\n",
      "           0, 1534,  789,  469,  220,  789,  469,    0,  413,   52,  295,   86,\n",
      "        1087,   76,  763,    0, 2715, 1409,  763, 1534,  789,  220, 2715,  220,\n",
      "           0,   76,  469,    0, 1535, 2715, 2787,   52,  764,   86, 2715,    0,\n",
      "          86,   52,   76, 1534,  789,  295,   86,    0,  413, 2715,  295, 2715,\n",
      "           0,  295, 2715, 2787, 2728, 2787, 1534,   76,  469,  887,    0,   52,\n",
      "         295,  152,   76, 1534, 1534, 2715,  295, 2728,    0, 2787,   52,  295,\n",
      "         152,  295,   76,  220,  887, 2715,   86,    0, 1534,   76, 2520, 2715,\n",
      "           0,  152, 2715, 2787, 1087]), tensor([  76,  469,    0,   77, 2715,   77,  789,  295, 2728,    0,  789, 2520,\n",
      "           0,  152, 1087, 2715,    0, 2185,   76, 2787,  152,   76,   77,   86,\n",
      "           0,  789, 2520,    0, 1087,   76,  295,  789,   86, 1087,   76,   77,\n",
      "          52,    0,   52,  469,  220,    0,  469,   52,  887,   52,   86,   52,\n",
      "         376,   76,    0,  469, 2715, 2185, 2715,  295,    0,   52,  887,   52,\n",
      "          76,  469,    0, 1535,   52,  469,    0,  469,  764, 2787, 1534, 2715,\n",
      "          52,  295,    0,  413, 2715,   52,  763,  789,  469,   86]), tensor([ 295, 2715,   52, 1534,   76,  152, 2728,    0,  152,  295,   52,   76,\n",
      "         469,   76,  469,  887,    0,  152,  295,   52,   76,  469,    0, 2520,\n",
      "          52, 1534, 1534,   86,    0,  789, 2520, 2520,    0, 2715, 1534, 2715,\n",
      "        2185,   52,  152, 2715,  220,    0,  152,  295,   52, 2787,  376,   86,\n",
      "           0,  220,  764,  295,   76,  469,  887,    0,  413,   76,  469,  220,\n",
      "          86,  152,  789,  295,   77]), tensor([ 413, 2715,  220,    0,   77,   52,   76,  469, 1534, 2728,    0, 2787,\n",
      "        1534,  789,  764,  220, 2728,    0,  763, 2715,  295, 2787, 2715,  469,\n",
      "         152,    0, 2787, 1087,   52,  469, 2787, 2715,    0,  789, 2520,    0,\n",
      "          86, 1087,  789,  413, 2715,  295,   86,    0,  152, 1087,   76,   86,\n",
      "           0, 2715, 2185, 2715,  469,   76,  469,  887,    0,  413,   76,  152,\n",
      "        1087,    0,  295,   76,   86,  376,    0,  789, 2520,    0,   52,    0,\n",
      "         152, 1087,  764,  469,  220, 2715,  295,   86,  152,  789,  295,   77,\n",
      "           0, 1534,  789,  413]), tensor([  76,  469, 2185, 2715,   86,  152,   76,  887,   52,  152,  789,  295,\n",
      "          86,    0,  295,  764, 1534, 2715,    0, 2787,   52,  152,   52,   86,\n",
      "         152,  295,  789,  763, 1087,   76, 2787,    0,   86,  152,  295,  764,\n",
      "        2787,  152,  764,  295,   52, 1534,    0, 2520,   52,   76, 1534,  764,\n",
      "         295, 2715,    0,  295, 2715,   86,  764, 1534,  152, 2715,  220,    0,\n",
      "          76,  469]), tensor([ 469, 2715,  413,    0,   86,  764,   77,   77, 2715,  295,    0, 1534,\n",
      "         789,  469,  887,    0,  152, 1087,   76,  469,    0, 1535,  789,  220,\n",
      "        2728,    0, 1535,   52,  887,    0, 1087,   76,  763,    0,   52,    0,\n",
      "         413,  789,  295,  220,    0,   86,  376,   76,  295,  152,    0, 1535,\n",
      "        1534,  764, 2715]), tensor([  77, 2715,  887,   52,  469, 1535, 2715, 2715,    0,  376,   52,  220,\n",
      "          76, 2715,  887,  295,  295,    0,   76,   77,    0, 1017,  764,   86,\n",
      "         152,    0,  220, 2715, 2185,   52,   86,  152,   52,  152, 2715,  220,\n",
      "           0,  152, 1087,   52,  152,    0,  413, 1087, 2715,  469,    0,   76,\n",
      "         152,    0, 2715,  469,  220,   86,    0,   76,    0,  413,   76, 1534,\n",
      "        1534,    0,  469,  789,    0, 1534,  789,  469,  887, 2715,  295,    0,\n",
      "          86, 2715, 2715,    0,  152, 2728, 1534, 2715,  295,    0, 1535, 1534,\n",
      "          52, 2787,  376, 1535,  764,  295,  469,   86,    0, 2520,   52, 2787,\n",
      "        2715,    0,  789,  469,    0,  763, 1534, 1534,    0, 1409, 1409, 1409]), tensor([ 764,  295,  764, 2520,  764,   86,   52,  469,  295,   52,  887,  764,\n",
      "           0,   52,    0,   77,  764,  220,   86, 1534,   76,  220, 2715]), tensor([ 152, 1087, 2715,  295, 2715,    0,   76,   86,    0,  152, 1087,   76,\n",
      "          86,    0,  789, 1534,  220,    0, 1534,   52,  220, 2728,    0,  295,\n",
      "         789, 2787,  376,   76,  469,    0,  789,  764,  152,    0,  152,  789,\n",
      "           0,  220, 2715,   52,  152, 1087,    0,   77, 2715,  152,   52, 1534,\n",
      "           0,   76,  469,    0, 1087, 2715,  295,    0,   86, 2715,  220,   52,\n",
      "         469,    0,  220,  789,  413,  469,  152,  789,  413,  469,    0,   86,\n",
      "          77,  789,  376,   76,  469,  887,    0,   52,    0, 2787,   76,  887,\n",
      "          52,  295, 2715,  152,  152, 2715,    0,   76,    0, 2520,  789,  764,\n",
      "         469,  220,    0,   77, 2728,    0,  295, 2715,   52, 1534,    0,   77,\n",
      "         789,   77]), tensor([  52, 2520,  152, 2715,  295,    0,   86, 1087,  789,  789,  152,   76,\n",
      "         469,  887,    0, 2715, 2185, 2715,  469,  152,    0,   52,  152,    0,\n",
      "         152, 1087, 2715,    0,  152, 1087, 2715,   52,  152, 2715,  295,    0,\n",
      "          86,  152,   52,  295, 1535,  764, 2787,  376,   86,    0,   76,   86,\n",
      "           0,  887,   76, 2185,   76,  469,  887,    0, 2520,  295, 2715, 2715,\n",
      "           0, 2787,  789, 2520, 2520, 2715, 2715,    0,  152,  789,    0,   52,\n",
      "        1534, 1534,    0, 2520,   76,  295,   86,  152,    0,  295, 2715,   86,\n",
      "         763,  789,  469,  220, 2715,  295,   86,    0,  763,  789, 1534,   76,\n",
      "        2787, 2715,    0,   52,   77,  763,    0, 2520,   76,  295, 2715, 2520,\n",
      "          76,  887, 1087,  152, 2715,  295,   86,    0,   52,  469,  152,   76,\n",
      "         789, 2787, 1087, 1087,   76, 2787,  376,  789,  295, 2728, 1087,  789,\n",
      "        1534, 1534,  789,  413,    0,  152,  469]), tensor([ 220,   52,  295, 2787, 1087,   52,   77, 1535,   52,  764,    0,  152,\n",
      "        1087, 1409,    0, 2520,  789,  295,    0, 2728,  789,  764,  295,    0,\n",
      "         887,  295, 2715,   52,  152,    0, 2715,  469, 2787,  789,  764,  295,\n",
      "          52,  887, 2715,   77, 2715,  469,  152,    0,   52,  469,  220,    0,\n",
      "        2520,  789,  295,    0,  295,  152,    0,  789, 2520,    0,  469, 2715,\n",
      "         413,    0, 2185,   76,  220, 2715,  789,    0,  152, 1087, 2715,    0,\n",
      "        2787,  789,   77,   76,  469,  887,    0,   52,  763,  789, 2787,   52,\n",
      "        1534, 2728,  763,  152,   76, 2787,    0,  764,   86,    0, 2715,   52,\n",
      "         295,  152, 1087, 2274,  764,   52,  376, 2715,    0,   52,   77,  763,\n",
      "           0,  152,   86,  764,  469,   52,   77,   76]), tensor([  76,    0, 2185, 2715,    0, 1017,  764,   86,  152,    0,  763,  789,\n",
      "          86,  152, 2715,  220,    0,  789,  469,    0,   77, 2728,    0, 1535,\n",
      "        1534,  789,  887,    0,   52, 1535,  789,  764,  152,    0, 2787,  295,\n",
      "          76,   77,   76,  469,   52, 1534,   86,    0,  413, 1087,  789,    0,\n",
      "        1087,   76, 1017,   52, 2787,  376,    0, 1534,  789,  295,  295,   76,\n",
      "        2715,   86,    0,   52,  469,  220,    0, 1535,  764,   86, 2715,   86,\n",
      "           0,   52,  295,  295, 2715,   86,  152, 2715,  220,    0,   76,  469,\n",
      "           0, 2715,  469,  764,  887,  764,    0,  763, 1087,  789,  152,  789])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for sequence element 6 in sequence argument at position #1 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-d38c7dd88887>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcurrentWeight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_valid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-e4a3c2e90d2f>\u001b[0m in \u001b[0;36mtrain_func\u001b[1;34m(sub_train_)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-943e870ce7fd>\u001b[0m in \u001b[0;36mgenerate_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moffsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for sequence element 6 in sequence argument at position #1 'tensors'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import random_split\n",
    "BATCH_SIZE = 32\n",
    "train_len = int(len(twitter_dateSet) * 0.90)\n",
    "sub_train_, sub_valid_ = random_split(twitter_dateSet, [train_len, len(twitter_dateSet) - train_len])\n",
    "\n",
    "for epoch in range(2):\n",
    "    start_time = time.time()\n",
    "    currentWeight = ffmodel.embedding.weight.clone()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = valid_func(sub_valid_)\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "    \n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')\n",
    "    \n",
    "    for i in range(len(ffmodel.embedding.weight)):\n",
    "        diff = torch.abs(currentWeight[i] - ffmodel.embedding.weight[i]) > 0.001\n",
    "        if (diff.any()):\n",
    "            print(currentWeight[i])\n",
    "            print(ffmodel.embedding.weight[i])\n",
    "            print(i)\n",
    "    print(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fun(sentence):\n",
    "    #print(\" input \" + sentence)\n",
    "    if len(sentence) == 0:\n",
    "        sentence = 'awesome'\n",
    "    tensor = twitter_dateSet.getTensor(sentence)\n",
    "    t1 = model(tensor, torch.tensor([0]))\n",
    "    t1 = t1.view(-1)\n",
    "    return t1[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idx[473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = twitter_dateSet.getTensor('this is fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"modelPredict\"] = train['text'].apply(lambda x : predict_fun(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fun('this is fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"modelDebugging.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = test['text'].apply(lambda x : predict_fun(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = (test['target'] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%f'%(2.2/1.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8])\n",
    "t2 = torch.tensor([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t1 == t2).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
